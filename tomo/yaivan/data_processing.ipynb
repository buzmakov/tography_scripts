{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division , print_function\n",
    "import os\n",
    "import glob\n",
    "import errno\n",
    "import ConfigParser\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pylab as plt\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "def find_tomo_config(data_root):\n",
    "    log_files = glob.glob(os.path.join(data_root,'*.log'))\n",
    "    if len(log_files) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        return log_files[0]\n",
    "    \n",
    "def read_config(config_path):\n",
    "    def as_dict(config):\n",
    "        d = dict(config._sections)\n",
    "        for k in d:\n",
    "            d[k] = dict(config._defaults, **d[k])\n",
    "            d[k].pop('__name__', None)\n",
    "        return d\n",
    "    \n",
    "    config = ConfigParser.RawConfigParser()\n",
    "    config.optionxform = str\n",
    "    config.read(config_path)\n",
    "    res = as_dict(config)\n",
    "    return res\n",
    "    \n",
    "def find_data_folders(data_root):\n",
    "    data_dirs = []\n",
    "    for root, dirs, files in os.walk(data_root):\n",
    "        if 'Raw' in dirs: # looking for 'Raw' subdirectory \n",
    "            data_dir = os.path.join(root, 'Raw')\n",
    "            log_files = find_tomo_config(data_dir) # try to find *.log files\n",
    "            if len(log_files) > 0:\n",
    "                data_dirs.append(root)\n",
    "    return data_dirs\n",
    "\n",
    "def check_datafiles(data_files):\n",
    "    for idf, df in enumerate(data_files):\n",
    "        if not '{:04d}.tif'.format(idf) in df:\n",
    "            raise ValueError('!!! File number {} missing. Found {}'.format(idf, df))\n",
    "            \n",
    "def write_projections_h5(out_file, data_files, overwrite=False):\n",
    "    if os.path.exists(out_file) and overwrite==False:\n",
    "        print('!!! File {} exist. Skiping write projections.'.format(out_file))\n",
    "    else:\n",
    "        print('Creating file: {}'.format(out_file))\n",
    "        test_data = plt.imread(data_files[0])\n",
    "        print('Size of projection image:', test_data.shape)\n",
    "        print('Image data type:', test_data.dtype)\n",
    "        print('Number of images:', len(data_files))\n",
    "        with h5py.File(out_file,'a') as h5f:\n",
    "            h5f.create_dataset('data', (len(data_files), test_data.shape[0], test_data.shape[1]),\n",
    "                chunks=True, dtype=test_data.dtype)\n",
    "            for idf, df in tqdm(enumerate(data_files)):\n",
    "                df = plt.imread(data_files[idf])\n",
    "                h5f['data'][idf]=df\n",
    "                \n",
    "def store_dict_hdf5(hdf5_file_name, input_dict):\n",
    "    \"\"\"\n",
    "    Store dictionary in hdf5 file.\n",
    "    \n",
    "    :param hdf5_file_name:\n",
    "    :param input_dict:\n",
    "    \"\"\"\n",
    "\n",
    "    def store_group(group, pearent_goup):\n",
    "        \"\"\"\n",
    "        Store group (not a value)in HDF5 file.\n",
    "        \n",
    "        :param group:\n",
    "        :param pearent_goup:\n",
    "        \"\"\"\n",
    "\n",
    "        for (k, v) in list(group.items()):\n",
    "            if isinstance(v, dict):\n",
    "                if k in pearent_goup:\n",
    "                    del pearent_goup[k]\n",
    "                tmp_group = pearent_goup.create_group(k)\n",
    "                store_group(v, tmp_group)\n",
    "            else:\n",
    "                store_value(k, v, pearent_goup)\n",
    "\n",
    "    def store_value(name, value, group):\n",
    "        \"\"\"\n",
    "        Store value (scalar, string, array, etc.) in HDF5 file\n",
    "        \n",
    "        :param name:\n",
    "        :param value:\n",
    "        :param group:\n",
    "        \"\"\"\n",
    "        if value is not None:\n",
    "            if name in group:\n",
    "                del group[name]\n",
    "            if '/' in name:\n",
    "                name = name.replace('/','')\n",
    "            try:\n",
    "                group.create_dataset(name, data=value, chunks=True,\n",
    "                                     compression='gzip', compression_opts=3\n",
    "                                     )\n",
    "            except ValueError:  # if h5py not support compression\n",
    "                group.create_dataset(name, data=value, chunks=True)\n",
    "            except TypeError:\n",
    "                group.create_dataset(name, data=value)\n",
    "            except Exception:\n",
    "                print(\"!!! Error at name='{}' value='{}' group='{}'\".format(name, value, group))\n",
    "                raise\n",
    "\n",
    "    with h5py.File(hdf5_file_name, 'a') as res_file:\n",
    "        store_group(input_dict, res_file)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_root = '/diskmnt/a/makov/yaivan' # path to folders with data\n",
    "    tomo_dirs = find_data_folders(data_root=data_root)\n",
    "    for tomo_dir in tomo_dirs:\n",
    "        raw_dir = os.path.join(tomo_dir,'Raw')\n",
    "        print('Tomo data dir:\\t', tomo_dir)\n",
    "        \n",
    "        config_file = find_tomo_config(raw_dir)\n",
    "        config = read_config(config_file)\n",
    "        \n",
    "        object_name = config['Acquisition']['Filename Prefix']\n",
    "        print('Object name:\\t', object_name)\n",
    "        \n",
    "        #find projections files\n",
    "        data_files  = glob.glob(os.path.join(raw_dir,object_name+'[0-9]'*4+'.tif'))\n",
    "        data_files = sorted(data_files)\n",
    "        print('Data files found:', len(data_files))\n",
    "        print('First file:', data_files[0])\n",
    "        print('Last file:', data_files[-1])\n",
    "        check_datafiles(data_files)\n",
    "        \n",
    "        \n",
    "        output_dir = os.path.join(tomo_dir,'_tmp')\n",
    "        mkdir_p(output_dir)\n",
    "        hdf5_file_name = os.path.join(output_dir, 'raw.h5')\n",
    "        #strote projections to 'data' dataset\n",
    "        write_projections_h5(hdf5_file_name, data_files)\n",
    "        \n",
    "        # store config\n",
    "        store_dict_hdf5(hdf5_file_name, {'config':config})\n",
    "        \n",
    "        #store drift map\n",
    "        drift_file = os.path.join(raw_dir, object_name+'_TS.crv')\n",
    "        if os.path.isfile(drift_file):\n",
    "            print('Store drift file:', drift_file)\n",
    "            drift_map = np.loadtxt(drift_file,skiprows=2)\n",
    "            store_dict_hdf5(hdf5_file_name, {'drift':drift_map})\n",
    "        else:\n",
    "            print('!!! Drift file not found:', drift_file)\n",
    "        \n",
    "        len(data_files)\n",
    "        print()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_root = '/diskmnt/a/makov/yaivan'\n",
    "!find {data_root} -type f -name raw.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
