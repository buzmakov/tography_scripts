{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "\n",
    "import os\n",
    "import errno\n",
    "import glob\n",
    "import ConfigParser\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "import astra\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.getLogger('').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = unicode(index or '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_config(config_path):\n",
    "    def as_dict(config):\n",
    "        d = dict(config._sections)\n",
    "        for k in d:\n",
    "            d[k] = dict(config._defaults, **d[k])\n",
    "            d[k].pop('__name__', None)\n",
    "        return d\n",
    "    \n",
    "    config = ConfigParser.RawConfigParser()\n",
    "    config.optionxform = str\n",
    "    config.read(config_path)\n",
    "    res = as_dict(config)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_root = '/diskmnt/a/makov/yaivan/MMC_1/'\n",
    "# nrecon_folder = os.path.join(data_root,'_tmp','nrecon', 'bh_92_rc_20')\n",
    "nrecon_root_folder = os.path.join(data_root,'_tmp','nrecon')\n",
    "astra_root_folder = os.path.join(data_root,'_tmp','astra')\n",
    "mkdir_p(astra_root_folder)\n",
    "\n",
    "LOG_FILENAME = os.path.join(astra_root_folder, 'astra_rec.out')\n",
    "\n",
    "my_logger = logging.getLogger('')\n",
    "my_logger.setLevel(logging.DEBUG)\n",
    "handler = logging.handlers.RotatingFileHandler(\n",
    "    LOG_FILENAME,  maxBytes=1e5, backupCount=5)\n",
    "formatter = logging.Formatter('%(asctime)-15s %(levelname)-8s %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "my_logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrecon_folders = glob.glob(os.path.join(nrecon_root_folder, '*'))\n",
    "nrecon_folders = [nf for nf in nrecon_folders if os.path.isdir(nf)]\n",
    "print len(nrecon_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_reconstruction_geomety(detector_size, angles):\n",
    "    \n",
    "    # proj_geom = astra.create_proj_geom('parallel', 1.0, detector_size, angles)\n",
    "    \n",
    "    #Object to Source (mm) = 56.135\n",
    "    #Camera to Source (mm) = 225.082\n",
    "    \n",
    "    # All distances in [pixels]\n",
    "    pixel_size = 2.82473e-3\n",
    "    os_distance = 56.135/pixel_size\n",
    "    ds_distance = 225.082/pixel_size\n",
    "    \n",
    "    proj_geom = astra.create_proj_geom('fanflat', ds_distance/os_distance, detector_size, angles,\n",
    "                                       os_distance, (ds_distance-os_distance))\n",
    "    return proj_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def astra_tomo2d_fanflat_fbp(sinogram, angles):\n",
    "    angles = angles.astype('float64') # hack for astra stability, may be removed in future releases\n",
    "    detector_size = sinogram.shape[1]\n",
    "    \n",
    "\n",
    "    rec_size = detector_size # size of reconstruction region\n",
    "    vol_geom = astra.create_vol_geom(rec_size, rec_size)\n",
    "\n",
    "    proj_geom = build_reconstruction_geomety(detector_size, angles)\n",
    "    \n",
    "    sinogram_id = astra.data2d.create('-sino', proj_geom, data=sinogram)\n",
    "    # Create a data object for the reconstruction\n",
    "    rec_id = astra.data2d.create('-vol', vol_geom)\n",
    "\n",
    "    # Set up the parameters for a reconstruction algorithm using the GPU\n",
    "    cfg = astra.astra_dict('FBP_CUDA')\n",
    "    cfg['ReconstructionDataId'] = rec_id\n",
    "    cfg['ProjectionDataId'] = sinogram_id\n",
    "    cfg['option'] = {}\n",
    "    cfg['option']['ShortScan'] = False\n",
    "#     cfg['option']['MinConstraint'] = 0\n",
    "    # cfg['option']['MaxConstraint'] = 5\n",
    "\n",
    "    # Available algorithms:\n",
    "    # SIRT_CUDA, SART_CUDA, EM_CUDA, FBP_CUDA (see the FBP sample)\n",
    "\n",
    "    # Create the algorithm object from the configuration structure\n",
    "    alg_id = astra.algorithm.create(cfg)\n",
    "\n",
    "    # Run 150 iterations of the algorithm\n",
    "    astra.algorithm.run(alg_id,  1)\n",
    "\n",
    "    # Get the result\n",
    "    rec = astra.data2d.get(rec_id)\n",
    "\n",
    "    # Clean up. Note that GPU memory is tied up in the algorithm object,\n",
    "    # and main RAM in the data objects.\n",
    "    astra.algorithm.delete(alg_id)\n",
    "    astra.data2d.delete(rec_id)\n",
    "    astra.data2d.delete(sinogram_id)\n",
    "    astra.clear()\n",
    "    return rec, proj_geom, cfg\n",
    "\n",
    "def astra_tomo2d_fanflat_sirt(sinogram, angles):\n",
    "    angles = angles.astype('float64') # hack for astra stability, may be removed in future releases\n",
    "    detector_size = sinogram.shape[1]\n",
    "    \n",
    "\n",
    "    rec_size = detector_size # size of reconstruction region\n",
    "    vol_geom = astra.create_vol_geom(rec_size, rec_size)\n",
    "\n",
    "    proj_geom = build_reconstruction_geomety(detector_size, angles)\n",
    "    \n",
    "    sinogram_id = astra.data2d.create('-sino', proj_geom, data=sinogram)\n",
    "    # Create a data object for the reconstruction\n",
    "    rec_id = astra.data2d.create('-vol', vol_geom)\n",
    "\n",
    "    # Set up the parameters for a reconstruction algorithm using the GPU\n",
    "    cfg = astra.astra_dict('SIRT_CUDA')\n",
    "    cfg['ReconstructionDataId'] = rec_id\n",
    "    cfg['ProjectionDataId'] = sinogram_id\n",
    "    cfg['option'] = {}\n",
    "#     cfg['option']['MinConstraint'] = 0\n",
    "    # cfg['option']['MaxConstraint'] = 5\n",
    "\n",
    "    # Available algorithms:\n",
    "    # SIRT_CUDA, SART_CUDA, EM_CUDA, FBP_CUDA (see the FBP sample)\n",
    "\n",
    "    # Create the algorithm object from the configuration structure\n",
    "    alg_id = astra.algorithm.create(cfg)\n",
    "\n",
    "    # Run 150 iterations of the algorithm\n",
    "    astra.algorithm.run(alg_id,  200)\n",
    "\n",
    "    # Get the result\n",
    "    rec = astra.data2d.get(rec_id)\n",
    "\n",
    "    # Clean up. Note that GPU memory is tied up in the algorithm object,\n",
    "    # and main RAM in the data objects.\n",
    "    astra.algorithm.delete(alg_id)\n",
    "    astra.data2d.delete(rec_id)\n",
    "    astra.data2d.delete(sinogram_id)\n",
    "    astra.clear()\n",
    "    return rec, proj_geom, cfg\n",
    "\n",
    "def astra_tomo2d_fanflat_sart(sinogram, angles):\n",
    "    angles = angles.astype('float64') # hack for astra stability, may be removed in future releases\n",
    "    detector_size = sinogram.shape[1]\n",
    "    \n",
    "\n",
    "    rec_size = detector_size # size of reconstruction region\n",
    "    vol_geom = astra.create_vol_geom(rec_size, rec_size)\n",
    "\n",
    "    proj_geom = build_reconstruction_geomety(detector_size, angles)\n",
    "    \n",
    "    sinogram_id = astra.data2d.create('-sino', proj_geom, data=sinogram)\n",
    "    # Create a data object for the reconstruction\n",
    "    rec_id = astra.data2d.create('-vol', vol_geom)\n",
    "\n",
    "    # Set up the parameters for a reconstruction algorithm using the GPU\n",
    "    cfg = astra.astra_dict('SART_CUDA')\n",
    "    cfg['ReconstructionDataId'] = rec_id\n",
    "    cfg['ProjectionDataId'] = sinogram_id\n",
    "    cfg['option'] = {}\n",
    "    cfg['option']['MinConstraint'] = 0\n",
    "    # cfg['option']['MaxConstraint'] = 5\n",
    "\n",
    "    # Available algorithms:\n",
    "    # SIRT_CUDA, SART_CUDA, EM_CUDA, FBP_CUDA (see the FBP sample)\n",
    "\n",
    "    # Create the algorithm object from the configuration structure\n",
    "    alg_id = astra.algorithm.create(cfg)\n",
    "\n",
    "    # Run 150 iterations of the algorithm\n",
    "    astra.algorithm.run(alg_id,  1000)\n",
    "\n",
    "    # Get the result\n",
    "    rec = astra.data2d.get(rec_id)\n",
    "\n",
    "    # Clean up. Note that GPU memory is tied up in the algorithm object,\n",
    "    # and main RAM in the data objects.\n",
    "    astra.algorithm.delete(alg_id)\n",
    "    astra.data2d.delete(rec_id)\n",
    "    astra.data2d.delete(sinogram_id)\n",
    "    astra.clear()\n",
    "    return rec, proj_geom, cfg\n",
    "\n",
    "# Define the plugin class (has to subclass astra.plugin.base)\n",
    "# Note that usually, these will be defined in a separate package/module\n",
    "class SIRTPlugin(astra.plugin.base):\n",
    "    \"\"\"Example of an ASTRA plugin class, implementing a simple 2D SIRT algorithm.\n",
    "\n",
    "    Options:\n",
    "\n",
    "    'rel_factor': relaxation factor (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # The astra_name variable defines the name to use to\n",
    "    # call the plugin from ASTRA\n",
    "    astra_name = \"SIRT-PLUGIN\"\n",
    "\n",
    "    def initialize(self,cfg, rel_factor = 1):\n",
    "        self.W = astra.OpTomo(cfg['ProjectorId'])\n",
    "        self.vid = cfg['ReconstructionDataId']\n",
    "        self.sid = cfg['ProjectionDataId']\n",
    "        self.rel = rel_factor\n",
    "\n",
    "    def run(self, its):\n",
    "        v = astra.data2d.get_shared(self.vid)\n",
    "        s = astra.data2d.get_shared(self.sid)\n",
    "        print s.shape\n",
    "        W = self.W\n",
    "        for i in range(its):\n",
    "            v[:] += self.rel*(W.T*(s - (W*v).reshape(s.shape))).reshape(v.shape)/s.size\n",
    "            \n",
    "# from plugin import SIRTPlugin            \n",
    "def astra_tomo2d_fanflat_plugin(sinogram, angles):\n",
    "    angles = angles.astype('float64') # hack for astra stability, may be removed in future releases\n",
    "    detector_size = sinogram.shape[1]\n",
    "    \n",
    "\n",
    "    rec_size = detector_size # size of reconstruction region\n",
    "    \n",
    "    vol_geom = astra.create_vol_geom(rec_size, rec_size)\n",
    "    proj_geom = build_reconstruction_geomety(detector_size, angles)\n",
    "    proj_id = astra.create_projector('cuda',proj_geom,vol_geom)\n",
    "    \n",
    "    sinogram_id = astra.data2d.create('-sino', proj_geom, data=sinogram)\n",
    "    # Create a data object for the reconstruction\n",
    "    rec_id = astra.data2d.create('-vol', vol_geom)\n",
    "    \n",
    "    astra.plugin.register(SIRTPlugin)\n",
    "    print astra.plugin.get_registered()\n",
    "    \n",
    "    # Set up the parameters for a reconstruction algorithm using the GPU\n",
    "    cfg = astra.astra_dict('SIRT-PLUGIN')\n",
    "    cfg['ProjectorId'] = proj_id\n",
    "    cfg['ReconstructionDataId'] = rec_id\n",
    "    cfg['ProjectionDataId'] = sinogram_id\n",
    "    cfg['option'] = {}\n",
    "    cfg['option']['rel_factor'] = 1.5\n",
    "#     cfg['option']['MinConstraint'] = 0\n",
    "    # cfg['option']['MaxConstraint'] = 5\n",
    "\n",
    "    # Available algorithms:\n",
    "    # SIRT_CUDA, SART_CUDA, EM_CUDA, FBP_CUDA (see the FBP sample)\n",
    "\n",
    "    # Create the algorithm object from the configuration structure\n",
    "    alg_id = astra.algorithm.create(cfg)\n",
    "\n",
    "    # Run 150 iterations of the algorithm\n",
    "    astra.algorithm.run(alg_id,  10)\n",
    "\n",
    "    # Get the result\n",
    "    rec = astra.data2d.get(rec_id)\n",
    "\n",
    "    # Clean up. Note that GPU memory is tied up in the algorithm object,\n",
    "    # and main RAM in the data objects.\n",
    "    astra.algorithm.delete(alg_id)\n",
    "    astra.data2d.delete(rec_id)\n",
    "    astra.data2d.delete(sinogram_id)\n",
    "    astra.clear()\n",
    "    return rec, proj_geom, cfg\n",
    "\n",
    "def create_sinogram(data, angles):  \n",
    "    angles = angles.astype('float64') # hack for astra stability, may be removed in future releases\n",
    "    detector_size = data.shape[1]\n",
    "\n",
    "    rec_size = detector_size # size of reconstruction region\n",
    "    vol_geom = astra.create_vol_geom(rec_size, rec_size)\n",
    "\n",
    "    proj_geom = build_reconstruction_geomety(detector_size, angles)\n",
    "    proj_id = astra.create_projector('cuda',proj_geom,vol_geom)\n",
    "    \n",
    "    W = astra.OpTomo(proj_id)\n",
    "    P = data\n",
    "    sinogram = W * P\n",
    "    sinogram = sinogram.reshape([len(angles), detector_size])\n",
    "    return np.rot90(sinogram,3)\n",
    "\n",
    "def get_reconstruction(sinogram, reconstruction_function, min_level=None):\n",
    "    angles = np.arange(sinogram.shape[0])*0.1#-11.493867*2\n",
    "    angles = angles.astype('float64')/180.*np.pi\n",
    "    if min_level is None:\n",
    "        astra_rec, proj_geom, cfg = reconstruction_function(np.flipud(sinogram), angles)\n",
    "    else:\n",
    "        astra_rec, proj_geom, cfg = reconstruction_function(np.flipud(sinogram), angles, min_level)\n",
    "    logging.info('Projection geometry: {}'.format(proj_geom))\n",
    "    logging.info('Reconstruction config: {}'.format(cfg))\n",
    "    astra_rec = np.flipud(astra_rec)\n",
    "    return astra_rec\n",
    "\n",
    "def get_reconstruction_fbp(sinogram):\n",
    "    return get_reconstruction(sinogram, astra_tomo2d_fanflat_fbp)\n",
    "\n",
    "def get_reconstruction_sirt(sinogram):\n",
    "    return get_reconstruction(sinogram, astra_tomo2d_fanflat_sirt)\n",
    "\n",
    "def get_reconstruction_sart(sinogram):\n",
    "    return get_reconstruction(sinogram, astra_tomo2d_fanflat_sart)\n",
    "\n",
    "def get_reconstruction_plugin(sinogram):\n",
    "    return get_reconstruction(sinogram, astra_tomo2d_fanflat_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for nrecon_folder in log_progress(nrecon_folders):\n",
    "#     data_file = os.path.join(nrecon_folder, 'MMC1_2.82um__sino0960.tif')\n",
    "    \n",
    "#     logging.info('Sinogram file: {}'.format(data_file))\n",
    "#     sinogram = plt.imread(data_file)\n",
    "#     logging.info('Sinogram angles, length: {}'.format(sinogram.shape))\n",
    "    \n",
    "#     nrecon_config_file = os.path.join(nrecon_folder, 'MMC1_2.82um__rec.log')\n",
    "#     nrecon_config = read_config(nrecon_config_file)\n",
    "    \n",
    "#     rec_sart = get_reconstruction_sart(sinogram)\n",
    "    \n",
    "#     output_folder = os.path.join(astra_root_folder, nrecon_folder[len(nrecon_root_folder)+1:])\n",
    "#     mkdir_p(output_folder)\n",
    "#     astra_sart_file = os.path.join(output_folder, 'MMC1_2.82um__rec0960_astra_sart.png')\n",
    "    \n",
    "    \n",
    "#     logging.info('Output file: {}'.format(astra_sart_file))\n",
    "#     plt.imsave(astra_sart_file, rec_sart, cmap = plt.cm.gray)\n",
    "    \n",
    "#     data_config = os.path.join(output_folder, 'MMC1_2.82um__rec.log')\n",
    "#     logging.info('Output config file: {}'.format(data_config))\n",
    "    \n",
    "#     config = ConfigParser.RawConfigParser()\n",
    "#     config.optionxform = str\n",
    "#     config.add_section('Reconstruction')\n",
    "#     config.set('Reconstruction', 'Minimum for CS to Image Conversion', rec_sart.min())\n",
    "#     config.set('Reconstruction', 'Maximum for CS to Image Conversion', rec_sart.max())\n",
    "    \n",
    "#     bh = nrecon_config['Reconstruction']['Beam Hardening Correction (%)']   \n",
    "#     rc = nrecon_config['Reconstruction']['Ring Artifact Correction']\n",
    "    \n",
    "#     config.set('Reconstruction', 'Beam Hardening Correction (%)', bh)\n",
    "#     config.set('Reconstruction', 'Ring Artifact Correction', rc)\n",
    "    \n",
    "#     with open(data_config, 'wb') as configfile:\n",
    "#         config.write(configfile)\n",
    "# #     # sinogram = sinogram[-1800:] \n",
    "# #     nrecon_rec_file = os.path.join(nrecon_folder,'MMC1_2.82um__rec0960.png')\n",
    "# #     nrecon_rec = plt.imread(nrecon_rec_file)[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrecon_folder = [d for d in nrecon_folders if 'bh_92_rc_20' in d][0]\n",
    "nrecon_rec = plt.imread(os.path.join(nrecon_folder, 'MMC1_2.82um__rec0960.png'))[...,0]\n",
    "nrecon_rec = nrecon_rec*(0.52+0.18)-0.18\n",
    "print nrecon_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.imshow(nrecon_rec, cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "# plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# buzmakov\n",
    "from numba import jit\n",
    "import logging\n",
    "from scipy import ndimage\n",
    "import skimage.io\n",
    "\n",
    "def calculate_background(data, zeros_mask):   \n",
    "    labeled_mask, num_features = ndimage.measurements.label(zeros_mask)\n",
    "    logging.info('Found regions: {}'.format(num_features-1))\n",
    "    sigma = []\n",
    "    for nf in range(num_features):\n",
    "        if nf == 0 :\n",
    "            continue\n",
    "        \n",
    "        data_constant = data[labeled_mask==nf]\n",
    "        s = np.std(data_constant)\n",
    "        sigma.append(s)\n",
    "        \n",
    "    logging.info('STD for regions: {}'.format(sigma))\n",
    "    std = np.mean(sigma)\n",
    "    logging.info('Mean STD for regions: {}'.format(std))\n",
    "    mean_value = data.mean()\n",
    "    logging.info('Mean reconstructed value for all data: {}'.format(mean_value))\n",
    "    res = std/mean_value\n",
    "    logging.info('Normalized STD: {}'.format(res))\n",
    "    return  res\n",
    "\n",
    "#ingacheva\n",
    "from scipy import misc\n",
    "from scipy import ndimage\n",
    "\n",
    "@jit\n",
    "def base_value(distance_transform, original):\n",
    "    delta = distance_transform.max() * 0.9\n",
    "    threshold =  distance_transform.max() - delta\n",
    "    xx = 1 * np.logical_and(distance_transform >= threshold, distance_transform > 0)\n",
    "    summ = xx.sum()\n",
    "    base_v = original[distance_transform >= threshold].sum() / summ\n",
    "    return base_v\n",
    "\n",
    "@jit\n",
    "def weighted_variance(mask, distance_transform, original):\n",
    "    base_v = base_value(distance_transform, original)\n",
    "    weight = np.zeros_like(mask)\n",
    "    weight[mask > 0.0] = np.sqrt(distance_transform[mask > 0.0])\n",
    "    threshold = distance_transform.max() * 0.8\n",
    "    xx = 1 * np.logical_and(distance_transform <= threshold, distance_transform > 0.0)\n",
    "    orig = np.zeros_like(mask)\n",
    "    orig = orig.astype('float64')\n",
    "    orig[xx > 0.0] = original[xx > 0.0] - base_v\n",
    "    res = weight[xx > 0.0] * np.power(orig[xx > 0.0], 2)\n",
    "    result = np.sqrt(res.sum() / weight[xx > 0.0].sum())\n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def calck_square(mask, distance_transform, original):\n",
    "    base_v = base_value(distance_transform, original)\n",
    "    iter_max = int(distance_transform.max())\n",
    "    sq = 0\n",
    "    for i in range(1, iter_max):\n",
    "        \n",
    "        value = original[(distance_transform>=i)*(distance_transform< i+1)].sum()\n",
    "        sq += np.abs(base_v - value)\n",
    "    sq =  sq / (base_v * iter_max)\n",
    "    return sq\n",
    "\n",
    "@jit\n",
    "def calculate_cupping(original, mask):\n",
    "    mask[mask > 0.0] = 1.0\n",
    "    labeled, nr_objects = ndimage.label(mask > 0.0)\n",
    "#     ndimage.find_objects(labeled)\n",
    "    logging.info('Number of objects is {}'.format(nr_objects))\n",
    "\n",
    "\n",
    "    result = 0\n",
    "    square = 0\n",
    "    for i in range(1, nr_objects+1):\n",
    "        mask[mask > 0.0] = 0.0\n",
    "        mask[labeled == i] = 1.0\n",
    "        \n",
    "        \n",
    "        sx = mask.sum(axis=0)\n",
    "        sxx = np.argwhere(sx>0)\n",
    "        x_min = sxx.min()\n",
    "        x_max = sxx.max()\n",
    "        \n",
    "        sy = mask.sum(axis=1)\n",
    "        syy = np.argwhere(sy>0)\n",
    "        y_min = syy.min()\n",
    "        y_max = syy.max()\n",
    "        \n",
    "        dist = ndimage.distance_transform_edt(mask[y_min:y_max, x_min:x_max])\n",
    "        \n",
    "\n",
    "        #res = weighted_variance(mask, dist, original)\n",
    "        #result += res\n",
    "        #data['weighted_variance'] = res\n",
    "\n",
    "        sq = calck_square(mask[y_min:y_max, x_min:x_max],\n",
    "                          dist,\n",
    "                          original[y_min:y_max, x_min:x_max])\n",
    "        square += sq\n",
    "        logging.info(\"square {} of the object {}\".format(sq, i))\n",
    "\n",
    "    #result = result / nr_objects\n",
    "    #print 'mean weighted variance ', result\n",
    "\n",
    "    square = square / nr_objects\n",
    "    return square\n",
    "\n",
    "mask_background = skimage.io.imread(\n",
    "    '/diskmnt/a/makov/yaivan/MMC_1/_tmp/binary_masks/MMC1_2.82um__rec0960_MASK_ZEROS_CONERS.png')[...,0]\n",
    "mask_cup = skimage.io.imread(\n",
    "    '/diskmnt/a/makov/yaivan/MMC_1/_tmp/binary_masks/MMC1_2.82um__rec0960_Mask_objects.png')[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(mask_background, cmap=plt.cm.viridis)\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_cup, cmap=plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file = os.path.join(nrecon_folder, 'MMC1_2.82um__sino0960.tif')\n",
    "sinogram = plt.imread(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(sinogram, cmap=plt.cm.viridis)\n",
    "plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rois = []\n",
    "rois.append(np.ix_(np.r_[2100:2350],np.r_[1700:2000]))\n",
    "rois.append(np.ix_(np.r_[2750:3200],np.r_[2350:2900]))\n",
    "rois.append(np.ix_(np.r_[2300:2380],np.r_[1200:1300]))\n",
    "rois.append(np.ix_(np.r_[2600:2750],np.r_[1100:1300]))\n",
    "rois.append(np.ix_(np.r_[2400:2900],np.r_[600:1000]))\n",
    "rois.append(np.ix_(np.r_[2700:3500],np.r_[1300:2100]))\n",
    "rois.append(np.ix_(np.r_[1450:2000],np.r_[600:1150]))\n",
    "rois.append(np.ix_(np.r_[1750:2050],np.r_[2500:2930]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def astra_my(sinogram, angles, min_level=0):\n",
    "    angles = angles.astype('float64') # hack for astra stability, may be removed in future releases\n",
    "    detector_size = sinogram.shape[1]\n",
    "    \n",
    "\n",
    "    rec_size = detector_size # size of reconstruction region\n",
    "    vol_geom = astra.create_vol_geom(rec_size, rec_size)\n",
    "\n",
    "    proj_geom = build_reconstruction_geomety(detector_size, angles)\n",
    "    \n",
    "    sinogram_id = astra.data2d.create('-sino', proj_geom, data=sinogram)\n",
    "    # Create a data object for the reconstruction\n",
    "    rec_id = astra.data2d.create('-vol', vol_geom)\n",
    "\n",
    "    # Set up the parameters for a reconstruction algorithm using the GPU\n",
    "    cfg = astra.astra_dict('SART_CUDA')\n",
    "    cfg['ReconstructionDataId'] = rec_id\n",
    "    cfg['ProjectionDataId'] = sinogram_id\n",
    "    cfg['option'] = {}\n",
    "    cfg['option']['MinConstraint'] = min_level\n",
    "    # cfg['option']['MaxConstraint'] = 5\n",
    "\n",
    "    # Available algorithms:\n",
    "    # SIRT_CUDA, SART_CUDA, EM_CUDA, FBP_CUDA (see the FBP sample)\n",
    "\n",
    "    # Create the algorithm object from the configuration structure\n",
    "    alg_id = astra.algorithm.create(cfg)\n",
    "\n",
    "    # Run 150 iterations of the algorithm\n",
    "    astra.algorithm.run(alg_id,  10000)\n",
    "\n",
    "    # Get the result\n",
    "    rec = astra.data2d.get(rec_id)\n",
    "\n",
    "    # Clean up. Note that GPU memory is tied up in the algorithm object,\n",
    "    # and main RAM in the data objects.\n",
    "    astra.algorithm.delete(alg_id)\n",
    "    astra.data2d.delete(rec_id)\n",
    "    astra.data2d.delete(sinogram_id)\n",
    "    astra.clear()\n",
    "    return rec, proj_geom, cfg\n",
    "\n",
    "def get_reconstruction_my(sinogram, min_level):\n",
    "    return get_reconstruction(sinogram, astra_my, min_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rec_my = rec_fbp\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.imshow(rec_my/(rec_my.max()-rec_my.min())-nrecon_rec/(nrecon_rec.max()-nrecon_rec.min()), cmap=plt.cm.gray)\n",
    "# plt.title('My')\n",
    "# plt.show()\n",
    "logging.getLogger('').setLevel(logging.ERROR)\n",
    "rec_fbp =  get_reconstruction_fbp(sinogram[-1800:])\n",
    "\n",
    "for min_level in log_progress(np.arange(-3,-1,1)):\n",
    "    print 'Min_level = {}'.format(min_level)\n",
    "    rec_my = get_reconstruction_my(sinogram, min_level)\n",
    "    \n",
    "\n",
    "    artifact_my_bg = calculate_background(rec_my, mask_background)\n",
    "    artifact_my_cup = calculate_cupping(rec_my, mask_cup)\n",
    "    print 'My: bg:{}, cup:{}'.format(artifact_my_bg, artifact_my_cup)\n",
    "\n",
    "    artifact_fbp_bg = calculate_background(rec_fbp, mask_background)\n",
    "    artifact_fbp_cup = calculate_cupping(rec_fbp, mask_cup)\n",
    "    print 'FBP: bg:{}, cup:{}'.format(artifact_fbp_bg, artifact_fbp_cup)\n",
    "\n",
    "    artifact_nrecon_bg = calculate_background(nrecon_rec, mask_background)\n",
    "    artifact_nrecon_cup = calculate_cupping(nrecon_rec, mask_cup)\n",
    "    print 'NRecon: bg:{}, cup:{}'.format(artifact_nrecon_bg, artifact_nrecon_cup)\n",
    "\n",
    "    for roi in rois:\n",
    "        d_my = rec_my[roi]\n",
    "        d_fbp = rec_fbp[roi]\n",
    "        d_nrecon = nrecon_rec[roi]\n",
    "\n",
    "        plt.figure(figsize=(15,15))\n",
    "\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(d_my, cmap=plt.cm.gray, vmin=0)\n",
    "        plt.title('My')\n",
    "\n",
    "        plt.subplot(222)\n",
    "        plt.imshow(d_fbp, cmap=plt.cm.gray, vmin=0)\n",
    "        plt.title('FBP')\n",
    "\n",
    "        plt.subplot(223)\n",
    "        plt.imshow(d_nrecon, cmap=plt.cm.gray, vmin=0)\n",
    "        plt.title('NRecon')\n",
    "\n",
    "        plt.subplot(224)\n",
    "        pos = int(d_my.shape[0]/2)\n",
    "        d_my_1 = d_my[pos]\n",
    "        d_my_1 = d_my_1/ (d_my_1.max()-d_my_1.min())\n",
    "\n",
    "        d_fbp_1 = d_fbp[pos]\n",
    "        d_fbp_1 = d_fbp_1/ (d_fbp_1.max()-d_fbp_1.min())\n",
    "\n",
    "        d_nrecon_1 = d_nrecon[pos]\n",
    "        d_nrecon_1 = d_nrecon_1/ (d_nrecon_1.max()-d_nrecon_1.min())\n",
    "\n",
    "\n",
    "        plt.plot(d_my_1, label='my')\n",
    "        plt.plot(d_fbp_1, label='FBP')\n",
    "        plt.plot(d_nrecon_1, label='NRecon')\n",
    "        plt.grid()\n",
    "        plt.legend(loc=0)\n",
    "        # plt.colorbar(orientation='horizontal')\n",
    "        plt.show()\n",
    "        \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(rec_my, cmap=plt.cm.gray)\n",
    "    plt.title('My')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(nrecon_rec, cmap=plt.cm.gray)\n",
    "    plt.title('NRecon')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
